{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Clean Data\n",
    "\n",
    "In this notebook, I undertake the task of cleaning data obtained from educational portals such as [Education Data Explorer](https://educationdata.urban.org/data-explorer), [Civil Rights Data](https://civilrightsdata.ed.gov/), and the [U.S. Department of Education](https://www2.ed.gov/about/inits/ed/edfacts/data-files/index.html). The aim is to prepare the data for further analysis by addressing inconsistencies, errors, and missing values.\n",
    "\n",
    "Given the diverse origins of the data and its storage in various tabular formats, I employ tailored cleaning procedures for each dataset. This involves tasks such as standardizing column names, correcting data types, handling outliers, and imputing missing values.\n",
    "\n",
    "Additionally, I implement quality checks and validation steps to ensure the integrity and accuracy of the cleaned data. By conducting thorough data cleaning processes, I strive to enhance the reliability and usability of the datasets for building informative dashboards."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5159c64c500bfc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load fips\n",
    "with open(\"./data/fips.json\") as file:\n",
    "    fips_dict = json.load(file)\n",
    "    \n",
    "# Fips dictionary\n",
    "fips_dict = {int(k):v for k,v in fips_dict.items()}\n",
    "\n",
    "# Race dictionary\n",
    "race_dict = {\n",
    "    1: \"White\",\n",
    "    2: \"Black\",\n",
    "    3: \"Hispanic\",\n",
    "    4: \"Asian\",\n",
    "    5: \"American Indian or Alaska Native\",\n",
    "}\n",
    "\n",
    "sex_dict = {\n",
    "    1: \"Male\",\n",
    "    2: \"Female\",\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:34:29.839918Z",
     "start_time": "2024-03-05T01:34:29.823833Z"
    }
   },
   "id": "982358a5d19f1bc9",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Demographic information\n",
    "\n",
    "Certain metrics in the Google Looker Studio dashboard necessitate data regarding the population in the diverse states of America and their demographics for the analyzed period. This data is sourced from [KFF](https://www.kff.org/)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d53392c123aa2a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# I need the FIPS number for each state\n",
    "inv_fips_dict = {v: int(k) for k, v in fips_dict.items()}\n",
    "\n",
    "# Read demographic data for each year\n",
    "df_dem_2011 = pd.read_csv(\"data/raw/kff/raw_data2011.csv\", skiprows=2)\n",
    "df_dem_2011[\"year\"] = 2011\n",
    "df_dem_2013 = pd.read_csv(\"data/raw/kff/raw_data2013.csv\", skiprows=2)\n",
    "df_dem_2013[\"year\"] = 2013\n",
    "df_dem_2015 = pd.read_csv(\"data/raw/kff/raw_data2015.csv\", skiprows=2)\n",
    "df_dem_2015[\"year\"] = 2015\n",
    "df_dem_2017 = pd.read_csv(\"data/raw/kff/raw_data2017.csv\", skiprows=2)\n",
    "df_dem_2017[\"year\"] = 2017\n",
    "df_dem_2021 = pd.read_csv(\"data/raw/kff/raw_data2021.csv\", skiprows=2)\n",
    "df_dem_2021[\"year\"] = 2020\n",
    "\n",
    "# Concatenate demographic data for all years\n",
    "df_dem = pd.concat([df_dem_2011, df_dem_2013, df_dem_2015, df_dem_2017, df_dem_2021])\n",
    "\n",
    "# Assign FIPS codes to each state\n",
    "df_dem[\"fips\"] = df_dem['Location'].apply(lambda x: inv_fips_dict[x] if x in inv_fips_dict else np.nan)\n",
    "df_dem.dropna(subset=['fips'], inplace=True)\n",
    "df_dem.fillna(0, inplace=True)\n",
    "df_dem[\"fips\"] = df_dem[\"fips\"].astype(int)\n",
    "\n",
    "# Add country and state information\n",
    "df_dem['country'] = \"United States\"\n",
    "df_dem[\"state\"] = df_dem['Location']\n",
    "df_dem = df_dem.rename(columns={\n",
    "    'American Indian/Alaska Native': 'American Indian or Alaska Native',\n",
    "    'Total': 'All'\n",
    "})\n",
    "\n",
    "# Assign date values\n",
    "df_dem[\"day\"] = 1\n",
    "df_dem[\"month\"] = 1\n",
    "df_dem['date'] = pd.to_datetime(df_dem[[\"year\", \"month\", \"day\"]])\n",
    "\n",
    "# Reshape the dataframe to have population values by race\n",
    "df_dem = df_dem.melt(id_vars=[\"year\", 'date', 'country', \"fips\", \"state\"],\n",
    "                     value_vars=['White', 'Black', 'Hispanic', 'American Indian or Alaska Native', 'All'],\n",
    "                     var_name='race_name', value_name='population')\n",
    "df_dem[\"population\"] = df_dem[\"population\"].astype(int)\n",
    "\n",
    "# Save the demographic data to a CSV file\n",
    "df_dem.to_csv(\"data/kff/population.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:34:29.868229Z",
     "start_time": "2024-03-05T01:34:29.840463Z"
    }
   },
   "id": "ef67dec8dc2cfe9b",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enrollment data\n",
    "\n",
    "I extract the enrollment data, transform it, and finally, load it into a CSV file. For this dataset, I have different files for each year (five files for 2011, 2013, 2015, 2017, and 2020)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4ef06d840e99d1e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for year in [2011, 2013, 2015, 2017, 2020]:\n",
    "    \n",
    "    # Load the data from the Urban Institute's Education Data portal\n",
    "    enroll_df = pd.read_csv(f\"https://educationdata.urban.org/csv/ccd/schools_ccd_enrollment_{year}.csv\")\n",
    "    \n",
    "    if not enroll_df.empty:\n",
    "        \n",
    "        # Remove unwanted data and handle missing values\n",
    "        enroll_df.loc[enroll_df[\"enrollment\"] < 0, \"enrollment\"] = np.nan\n",
    "        enroll_df.loc[enroll_df[\"fips\"] < 0, \"fips\"] = np.nan\n",
    "        enroll_df.loc[enroll_df[\"grade\"] < 1, \"grade\"] = np.nan\n",
    "        enroll_df.loc[enroll_df[\"grade\"] > 13, \"grade\"] = np.nan\n",
    "        \n",
    "        # Add state, race, and sex name based on dictionaries\n",
    "        enroll_df[\"state\"] = enroll_df['fips'].apply(lambda x: fips_dict[x] if x in fips_dict else np.nan)\n",
    "        enroll_df[\"race_name\"] = enroll_df['race'].apply(lambda x: race_dict[x] if x in race_dict else np.nan)\n",
    "        enroll_df[\"sex_name\"] = enroll_df['sex'].apply(lambda x: sex_dict[x] if x in sex_dict else np.nan)\n",
    "        \n",
    "        # Drop rows with missing values in specific columns\n",
    "        enroll_df.dropna(subset=[\"grade\", 'enrollment', 'fips', 'state', 'race_name', 'sex_name'], inplace=True)\n",
    "        \n",
    "        # Fix datatype\n",
    "        enroll_df[\"grade\"] = enroll_df[\"grade\"].astype(int)\n",
    "        enroll_df[\"enrollment\"] = enroll_df[\"enrollment\"].astype(int)\n",
    "        \n",
    "        # Add new columns for country, day, and month\n",
    "        enroll_df['country'] = \"United States\"\n",
    "        enroll_df[\"day\"] = 1\n",
    "        enroll_df[\"month\"] = 1\n",
    "        enroll_df['date'] = pd.to_datetime(enroll_df[[\"year\",\"month\",\"day\"]])\n",
    "        \n",
    "        # Aggregate data to a state level from a school level\n",
    "        enroll_df = enroll_df.groupby([\"year\", 'date', 'country', \"fips\", \"state\", \"grade\", \"race\", 'race_name', \"sex\", 'sex_name'], as_index=False).agg({\"enrollment\": \"sum\"})\n",
    "        \n",
    "        # Save the cleaned data to a CSV file for the year\n",
    "        enroll_df.to_csv(f\"data/raw/urban_institute/ccd_schools_states_enrollment_{year}.csv\", index=False)\n",
    "        del enroll_df  # Clean up the dataframe from memory after saving\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:39:01.139147Z",
     "start_time": "2024-03-05T01:34:29.866446Z"
    }
   },
   "id": "41ce4df60990a145",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "enrollment_list = []\n",
    "for year in [2011, 2013, 2015, 2017, 2020]:\n",
    "    \n",
    "    # Read the CSV file for the current year and append it to the list\n",
    "    enrollment_list.append(pd.read_csv(f\"data/raw/urban_institute/ccd_schools_states_enrollment_{year}.csv\"))\n",
    "\n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "df_enrollment_out = pd.concat(enrollment_list)\n",
    "\n",
    "# Write the concatenated DataFrame to a CSV file\n",
    "df_enrollment_out.to_csv(\"data/urban_institute/ccd_schools_states_enrollment.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:39:01.235303Z",
     "start_time": "2024-03-05T01:39:01.139062Z"
    }
   },
   "id": "e99157557c55b1c7",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "I calculate the Diversity Index similar to the US census, and also how many enrollments are per capita. Both calculations are saved in a separate file to the previous one because Google Looker needs the data in a specific way."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5775d04a3587090"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the diversity index (Simpson Index)\n",
    "\n",
    "df_enrollment_last_year = df_enrollment_out.groupby([\"year\", 'country', \"state\", \"race\", 'race_name'], as_index=False).agg(\n",
    "    {\"enrollment\": \"sum\"})\n",
    "\n",
    "# Filter for data from the last year in the dataset\n",
    "df_enrollment_last_year = df_enrollment_last_year[df_enrollment_last_year[\"year\"] > 2019]\n",
    "\n",
    "# Group by year, country, and state and aggregate total enrollment to obtain the enrollment by state\n",
    "df_enrollment_total = df_enrollment_last_year.groupby([\"year\", 'country', \"state\"], as_index=False).agg({\"enrollment\": \"sum\"})\n",
    "df_enrollment_total = df_enrollment_total.rename(columns={\"enrollment\": \"enrollment_total\"})\n",
    "\n",
    "# Merge the total enrollment data back into the DataFrame\n",
    "df_enrollment_last_year = df_enrollment_last_year.merge(right=df_enrollment_total, on=[\"year\", 'country', \"state\"])\n",
    "\n",
    "# Calculate the proportion of enrollment for each race within each state\n",
    "df_enrollment_last_year[\"p\"] = df_enrollment_last_year[\"enrollment\"] / df_enrollment_last_year[\"enrollment_total\"]\n",
    "\n",
    "# Apply the Simpson Index formula (Σ(p^2))\n",
    "df_enrollment_last_year[\"p2\"] = df_enrollment_last_year[\"p\"] ** 2\n",
    "df_enrollment_last_year = df_enrollment_last_year.groupby([\"year\", 'country', \"state\"], as_index=False).agg({\"enrollment\": \"sum\", \"p2\": \"sum\"})\n",
    "\n",
    "# Calculate the diversity index using the formula 1 - Σ(p^2)\n",
    "df_enrollment_last_year[\"diversity_index\"] = 1 - df_enrollment_last_year[\"p2\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:39:01.248505Z",
     "start_time": "2024-03-05T01:39:01.237593Z"
    }
   },
   "id": "d398ace57c1f7bdf",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read population data from the provided CSV file\n",
    "df_dem = pd.read_csv(\"data/kff/population.csv\")\n",
    "\n",
    "# Group population data by year, country, and state and aggregate total population\n",
    "df_dem = df_dem.groupby([\"year\", 'country', \"state\"], as_index=False).agg({\"population\": \"sum\"})\n",
    "\n",
    "# Filter for data from the last year in the dataset\n",
    "df_dem = df_dem[df_dem[\"year\"] > 2019]\n",
    "\n",
    "# Merge enrollment data with population data using year, country, and state as keys\n",
    "df_enrollment_last_year = df_enrollment_last_year.merge(right=df_dem, on=[\"year\", 'country', \"state\"])\n",
    "\n",
    "# Calculate enrollment per capita by dividing enrollment by population\n",
    "df_enrollment_last_year[\"enroll_per_capita\"] = df_enrollment_last_year[\"enrollment\"] / df_enrollment_last_year[\"population\"]\n",
    "\n",
    "# Write the resulting DataFrame to a new CSV file\n",
    "df_enrollment_last_year.to_csv(\"data/urban_institute/crdc_schools_states_enrollment_state_diversity_index.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:39:01.258799Z",
     "start_time": "2024-03-05T01:39:01.249912Z"
    }
   },
   "id": "e6830d10999bc41b",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assessment information\n",
    "\n",
    "I extract the assessment data, transform it, and finally, load it into a CSV file. For this dataset, I have different files for each year (five files for 2011, 2013, 2015, 2017, and 2020)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "572107061d44f45e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for year in [2011, 2013, 2015, 2017, 2020]:\n",
    "    \n",
    "    assessment_df = pd.read_csv(f\"https://educationdata.urban.org/csv/edfacts/schools_edfacts_assessments_{year}.csv\")\n",
    "    \n",
    "    if not assessment_df.empty:\n",
    "        \n",
    "        # Remove unwanted data and handle missing values\n",
    "        assessment_df.loc[assessment_df[\"fips\"] < 0, \"fips\"] = np.nan\n",
    "        \n",
    "        assessment_df = assessment_df[assessment_df[\"grade_edfacts\"] == 99]\n",
    "        assessment_df = assessment_df[assessment_df[\"lep\"] == 99]\n",
    "        assessment_df = assessment_df[assessment_df[\"homeless\"] == 99]\n",
    "        assessment_df = assessment_df[assessment_df[\"migrant\"] == 99]\n",
    "        assessment_df = assessment_df[assessment_df[\"disability\"] == 99]\n",
    "        assessment_df = assessment_df[assessment_df[\"econ_disadvantaged\"] == 99]\n",
    "        assessment_df = assessment_df[assessment_df[\"foster_care\"] == 99]\n",
    "        assessment_df = assessment_df[assessment_df[\"military_connected\"] == 99]\n",
    "        assessment_df = assessment_df[assessment_df[\"sex\"] == 99]\n",
    "        \n",
    "        assessment_df = assessment_df[assessment_df[\"read_test_num_valid\"] > 0]\n",
    "        assessment_df = assessment_df[assessment_df[\"read_test_pct_prof_low\"] > 0]\n",
    "        assessment_df = assessment_df[assessment_df[\"read_test_pct_prof_midpt\"] > 0]\n",
    "        assessment_df = assessment_df[assessment_df[\"read_test_pct_prof_high\"] > 0]\n",
    "        \n",
    "        assessment_df = assessment_df[assessment_df[\"math_test_num_valid\"] > 0]\n",
    "        assessment_df = assessment_df[assessment_df[\"math_test_pct_prof_low\"] > 0]\n",
    "        assessment_df = assessment_df[assessment_df[\"math_test_pct_prof_midpt\"] > 0]\n",
    "        assessment_df = assessment_df[assessment_df[\"math_test_pct_prof_high\"] > 0]\n",
    "        \n",
    "        assessment_df = assessment_df[assessment_df[\"race\"] < 80]\n",
    "        assessment_df = assessment_df[assessment_df[\"race\"] > 0]\n",
    "        \n",
    "        # Add state and race based on dictionaries\n",
    "        assessment_df[\"state\"] = assessment_df['fips'].apply(lambda x: fips_dict[x] if x in fips_dict else np.nan)\n",
    "        assessment_df[\"race_name\"] = assessment_df['race'].apply(lambda x: race_dict[x] if x in race_dict else np.nan)\n",
    "        \n",
    "        # Drop rows with missing values in specific columns\n",
    "        assessment_df.dropna(subset=[\"grade_edfacts\", 'fips', 'state', 'race_name'], inplace=True)\n",
    "        \n",
    "        # Fix datatype\n",
    "        assessment_df[\"grade\"] = assessment_df[\"grade_edfacts\"].astype(int)\n",
    "        assessment_df[\"read_test_num_valid\"] = assessment_df[\"read_test_num_valid\"].astype(int)\n",
    "        assessment_df[\"math_test_num_valid\"] = assessment_df[\"math_test_num_valid\"].astype(int)\n",
    "        \n",
    "        # Add new columns for country, day, and month\n",
    "        assessment_df['country'] = \"United States\"\n",
    "        assessment_df[\"day\"] = 1\n",
    "        assessment_df[\"month\"] = 1\n",
    "        assessment_df['date'] = pd.to_datetime(assessment_df[[\"year\",\"month\",\"day\"]])\n",
    "          \n",
    "        # Aggregate data to a state level from a school level\n",
    "        assessment_df = assessment_df.groupby([\"year\", 'date', 'country', \"fips\", \"state\", \"grade\", \"race\", 'race_name'], as_index=False).agg({\n",
    "            \"read_test_num_valid\": \"sum\",\n",
    "            'read_test_pct_prof_low': \"mean\",\n",
    "            'read_test_pct_prof_midpt': \"mean\",\n",
    "            'read_test_pct_prof_high': \"mean\",\n",
    "            \n",
    "            \"math_test_num_valid\": \"sum\",\n",
    "            'math_test_pct_prof_low': \"mean\",\n",
    "            'math_test_pct_prof_midpt': \"mean\",\n",
    "            'math_test_pct_prof_high': \"mean\",\n",
    "        })\n",
    "        \n",
    "        # Save the cleaned data to a CSV file for the year\n",
    "        assessment_df.to_csv(f\"data/raw/urban_institute/edfacts_schools_states_assessments_{year}.csv\", index=False)\n",
    "        del assessment_df  # Clean up the dataframe from memory after saving"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:41:19.956178Z",
     "start_time": "2024-03-05T01:39:01.262703Z"
    }
   },
   "id": "b75dd2f50967bf16",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assessment_list = []\n",
    "for year in [2011, 2013, 2015, 2017, 2020]:\n",
    "    \n",
    "    # Read the CSV file for the current year and append it to the list\n",
    "    assessment_list.append(pd.read_csv(f\"data/raw/urban_institute/edfacts_schools_states_assessments_{year}.csv\"))\n",
    "    \n",
    "# Concatenate all DataFrames in the list into a single DataFrame\n",
    "df_assessment_out = pd.concat(assessment_list)\n",
    "\n",
    "# Fix datatype\n",
    "df_assessment_out[\"read_test_num_valid\"] = df_assessment_out[\"read_test_num_valid\"].astype(int)\n",
    "df_assessment_out[\"read_test_pct_prof_low\"] = df_assessment_out[\"read_test_pct_prof_low\"].astype(int)\n",
    "df_assessment_out[\"read_test_pct_prof_midpt\"] = df_assessment_out[\"read_test_pct_prof_midpt\"].astype(int)\n",
    "df_assessment_out[\"read_test_pct_prof_high\"] = df_assessment_out[\"read_test_pct_prof_high\"].astype(int)\n",
    "df_assessment_out[\"math_test_num_valid\"] = df_assessment_out[\"math_test_num_valid\"].astype(int)\n",
    "df_assessment_out[\"math_test_pct_prof_low\"] = df_assessment_out[\"math_test_pct_prof_low\"].astype(int)\n",
    "df_assessment_out[\"math_test_pct_prof_midpt\"] = df_assessment_out[\"math_test_pct_prof_midpt\"].astype(int)\n",
    "df_assessment_out[\"math_test_pct_prof_high\"] = df_assessment_out[\"math_test_pct_prof_high\"].astype(int)\n",
    "\n",
    "# Write the concatenated DataFrame to a CSV file\n",
    "df_assessment_out.to_csv(\"data/urban_institute/edfacts_schools_states_assessments.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:41:19.975070Z",
     "start_time": "2024-03-05T01:41:19.953920Z"
    }
   },
   "id": "b1b684d43b1e40b6",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create separate CSV files for the assessment data without racial information and for the grade balance graph in the Google Looker Studio dashboard."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0a9e68b0f83608c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Aggregate assessment data without considering race\n",
    "df_assessment_no_race = df_assessment_out.groupby([\"year\", \"date\", 'country', \"state\"], as_index=False).agg({\n",
    "    \"read_test_num_valid\": \"sum\",\n",
    "    \"read_test_pct_prof_midpt\": \"median\",\n",
    "    \"math_test_num_valid\": \"sum\",\n",
    "    \"math_test_pct_prof_midpt\": \"median\"\n",
    "})\n",
    "\n",
    "# Write the aggregated assessment data to a CSV file\n",
    "df_assessment_no_race.to_csv(\"data/urban_institute/edfacts_schools_states_assessments_no_race.csv\")\n",
    "\n",
    "# Data for the balanced between Math and Reading graph. \n",
    "# Rename columns and reshape the DataFrame to have separate columns for Math and Reading exam grade medians\n",
    "df_assessment_out[\"Maths Exam Grade Median\"] = df_assessment_out[\"math_test_pct_prof_midpt\"]\n",
    "df_assessment_out[\"Reading Exam Grade Median\"] = df_assessment_out[\"read_test_pct_prof_midpt\"]\n",
    "df_assessment_medians = pd.melt(df_assessment_out, id_vars=[\"year\", \"date\", 'country', \"state\", \"race_name\"],\n",
    "                               value_vars=[\"Maths Exam Grade Median\", \"Reading Exam Grade Median\"], var_name=\"Subject\",\n",
    "                               value_name='Exam Grade', col_level=None, ignore_index=True)\n",
    "# Write the reshaped DataFrame to a CSV file\n",
    "df_assessment_medians.to_csv(\"data/urban_institute/edfacts_schools_states_assessments_medians.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:41:19.999045Z",
     "start_time": "2024-03-05T01:41:19.977899Z"
    }
   },
   "id": "ee85d75bfa774a74",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Discipline Dataset\n",
    "\n",
    "I extract the discipline data, transform it, and finally, load it into a CSV file. For this dataset, I have different files for each year (four files for 2011, 2013, 2015, 2017)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e766529993fa841"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/q05bl7gj7jxb0qq6rb67fp4m0000gn/T/ipykernel_9159/524524948.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  discipline_df = pd.read_csv(f\"https://educationdata.urban.org/csv/crdc/schools_crdc_discipline_k12_{year}.csv\")\n",
      "/var/folders/50/q05bl7gj7jxb0qq6rb67fp4m0000gn/T/ipykernel_9159/524524948.py:3: DtypeWarning: Columns (0,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  discipline_df = pd.read_csv(f\"https://educationdata.urban.org/csv/crdc/schools_crdc_discipline_k12_{year}.csv\")\n",
      "/var/folders/50/q05bl7gj7jxb0qq6rb67fp4m0000gn/T/ipykernel_9159/524524948.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  discipline_df = pd.read_csv(f\"https://educationdata.urban.org/csv/crdc/schools_crdc_discipline_k12_{year}.csv\")\n",
      "/var/folders/50/q05bl7gj7jxb0qq6rb67fp4m0000gn/T/ipykernel_9159/524524948.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  discipline_df = pd.read_csv(f\"https://educationdata.urban.org/csv/crdc/schools_crdc_discipline_k12_{year}.csv\")\n"
     ]
    }
   ],
   "source": [
    "for year in [2011, 2013, 2015, 2017]:\n",
    "    \n",
    "    discipline_df = pd.read_csv(f\"https://educationdata.urban.org/csv/crdc/schools_crdc_discipline_k12_{year}.csv\")\n",
    "    \n",
    "    if not discipline_df.empty:\n",
    "        \n",
    "        # Remove unwanted data and handle missing values\n",
    "        discipline_df.loc[discipline_df[\"fips\"] < 0, \"fips\"] = np.nan\n",
    "        \n",
    "        # Set negative student suspension counts to zero\n",
    "        discipline_df.loc[discipline_df[\"students_susp_in_sch\"] < 0, \"students_susp_in_sch\"] = 0\n",
    "        discipline_df.loc[discipline_df[\"students_susp_out_sch_single\"] < 0, \"students_susp_out_sch_single\"] = 0\n",
    "        discipline_df.loc[discipline_df[\"students_susp_out_sch_multiple\"] < 0, \"students_susp_out_sch_multiple\"] = 0\n",
    "        discipline_df.loc[discipline_df[\"expulsions_no_ed_serv\"] < 0, \"expulsions_no_ed_serv\"] = 0\n",
    "        discipline_df.loc[discipline_df[\"expulsions_with_ed_serv\"] < 0, \"expulsions_with_ed_serv\"] = 0\n",
    "        discipline_df.loc[discipline_df[\"expulsions_zero_tolerance\"] < 0, \"expulsions_zero_tolerance\"] = 0\n",
    "        discipline_df.loc[discipline_df[\"students_corporal_punish\"] < 0, \"students_corporal_punish\"] = 0\n",
    "        discipline_df.loc[discipline_df[\"students_arrested\"] < 0, \"students_arrested\"] = 0\n",
    "        discipline_df.loc[discipline_df[\"students_referred_law_enforce\"] < 0, \"students_referred_law_enforce\"] = 0\n",
    "        discipline_df.loc[discipline_df[\"transfers_alt_sch_disc\"] < 0, \"transfers_alt_sch_disc\"] = 0\n",
    "        \n",
    "        # Fill NaN values with zero for certain columns\n",
    "        discipline_df[\"students_susp_in_sch\"] = discipline_df[\"students_susp_in_sch\"].fillna(0)\n",
    "        discipline_df[\"students_susp_out_sch_single\"] = discipline_df[\"students_susp_out_sch_single\"].fillna(0)\n",
    "        discipline_df[\"students_susp_out_sch_multiple\"] = discipline_df[\"students_susp_out_sch_multiple\"].fillna(0)\n",
    "        discipline_df[\"expulsions_no_ed_serv\"] = discipline_df[\"expulsions_no_ed_serv\"].fillna(0)\n",
    "        discipline_df[\"expulsions_with_ed_serv\"] = discipline_df[\"expulsions_with_ed_serv\"].fillna(0)\n",
    "        discipline_df[\"expulsions_zero_tolerance\"] = discipline_df[\"expulsions_zero_tolerance\"].fillna(0)\n",
    "        discipline_df[\"students_corporal_punish\"] = discipline_df[\"students_corporal_punish\"].fillna(0)\n",
    "        discipline_df[\"students_arrested\"] = discipline_df[\"students_arrested\"].fillna(0)\n",
    "        discipline_df[\"students_referred_law_enforce\"] = discipline_df[\"students_referred_law_enforce\"].fillna(0)\n",
    "        discipline_df[\"transfers_alt_sch_disc\"] = discipline_df[\"transfers_alt_sch_disc\"].fillna(0)\n",
    "        \n",
    "        # Convert certain columns to integer type\n",
    "        discipline_df[\"students_susp_in_sch\"] = discipline_df[\"students_susp_in_sch\"].astype(int)\n",
    "        discipline_df[\"students_susp_out_sch_single\"] = discipline_df[\"students_susp_out_sch_single\"].astype(int)\n",
    "        discipline_df[\"students_susp_out_sch_multiple\"] = discipline_df[\"students_susp_out_sch_multiple\"].astype(int)\n",
    "        discipline_df[\"expulsions_no_ed_serv\"] = discipline_df[\"expulsions_no_ed_serv\"].astype(int)\n",
    "        discipline_df[\"expulsions_with_ed_serv\"] = discipline_df[\"expulsions_with_ed_serv\"].astype(int)\n",
    "        discipline_df[\"expulsions_zero_tolerance\"] = discipline_df[\"expulsions_zero_tolerance\"].astype(int)\n",
    "        discipline_df[\"students_corporal_punish\"] = discipline_df[\"students_corporal_punish\"].astype(int)\n",
    "        discipline_df[\"students_arrested\"] = discipline_df[\"students_arrested\"].astype(int)\n",
    "        discipline_df[\"students_referred_law_enforce\"] = discipline_df[\"students_referred_law_enforce\"].astype(int)\n",
    "        discipline_df[\"transfers_alt_sch_disc\"] = discipline_df[\"transfers_alt_sch_disc\"].astype(int)\n",
    "        \n",
    "        # Filter the data for students with no disability or LEP status \n",
    "        discipline_df = discipline_df[discipline_df[\"disability\"] == 99]\n",
    "        discipline_df = discipline_df[discipline_df[\"lep\"] == 99]\n",
    "        \n",
    "        # Create new columns for aggregated disciplinary actions\n",
    "        \n",
    "        # Combine out-of-school suspension counts\n",
    "        discipline_df[\"students_susp_out_sch\"] = discipline_df[\"students_susp_out_sch_multiple\"] + discipline_df[\"students_susp_out_sch_single\"]\n",
    "        # Combine different types of expulsions\n",
    "        discipline_df[\"students_expulsions\"] = discipline_df[\"expulsions_no_ed_serv\"] + discipline_df[\"expulsions_with_ed_serv\"] + discipline_df[\"expulsions_zero_tolerance\"]\n",
    "        # Combine students arrested and referred to law enforcement\n",
    "        discipline_df[\"students_arrested\"] = discipline_df[\"students_arrested\"] + discipline_df[\"students_referred_law_enforce\"]\n",
    "        \n",
    "        # Map FIPS codes to state names\n",
    "        discipline_df[\"state\"] = discipline_df['fips'].apply(lambda x: fips_dict[x] if x in fips_dict else np.nan)\n",
    "        # Map race codes to race names\n",
    "        discipline_df[\"race_name\"] = discipline_df['race'].apply(lambda x: race_dict[x] if x in race_dict else np.nan)\n",
    "        # Map sex codes to sex names\n",
    "        discipline_df[\"sex_name\"] = discipline_df['sex'].apply(lambda x: sex_dict[x] if x in sex_dict else np.nan)\n",
    "        \n",
    "        # Drop rows with missing values in specific columns\n",
    "        discipline_df.dropna(subset=['fips', 'state', 'race_name', 'sex_name'], inplace=True)\n",
    "        \n",
    "        # Add columns for country, day, and month\n",
    "        discipline_df['country'] = \"United States\"\n",
    "        discipline_df[\"day\"] = 1\n",
    "        discipline_df[\"month\"] = 1\n",
    "        discipline_df['date'] = pd.to_datetime(discipline_df[[\"year\",\"month\",\"day\"]])\n",
    "        \n",
    "        # Aggregate data by year, date, country, FIPS code, state, race, and sex\n",
    "        discipline_df = discipline_df.groupby([\"year\", 'date', 'country', \"fips\", \"state\", \"race\", 'race_name', \"sex\", 'sex_name'], as_index=False).agg({\n",
    "            \"students_susp_in_sch\": \"sum\",\n",
    "            \"students_susp_out_sch\": \"sum\",\n",
    "            \"students_expulsions\": \"sum\",\n",
    "            \"students_corporal_punish\": \"sum\",\n",
    "            \"students_arrested\": \"sum\",\n",
    "            \"transfers_alt_sch_disc\": \"sum\",\n",
    "        })\n",
    "        \n",
    "        # Write the cleaned and aggregated data to a CSV file\n",
    "        discipline_df.to_csv(f\"data/raw/urban_institute/crdc_schools_states_discipline_{year}.csv\", index=False)\n",
    "        del discipline_df  # Delete the DataFrame to free up memory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:54.700680Z",
     "start_time": "2024-03-05T01:41:19.997327Z"
    }
   },
   "id": "e7443fc989e3763e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "discipline_list = []\n",
    "for year in [2011, 2013, 2015, 2017, 2020]:\n",
    "        \n",
    "    if year < 2020:\n",
    "        discipline_list.append(pd.read_csv(f\"data/raw/urban_institute/crdc_schools_states_discipline_{year}.csv\"))\n",
    "    else:\n",
    "        # Read the discipline data for the year 2017 and copy as 2020\n",
    "        df_temp = pd.read_csv(\"data/raw/urban_institute/crdc_schools_states_discipline_2017.csv\")\n",
    "        df_temp[\"year\"] = 2020\n",
    "        df_temp[\"day\"] = 1\n",
    "        df_temp[\"month\"] = 1\n",
    "        df_temp['date'] = pd.to_datetime(df_temp[[\"year\",\"month\",\"day\"]])\n",
    "        df_temp['date'] = df_temp['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "        df_temp.drop(columns=['day', 'month'], inplace=True)\n",
    "        discipline_list.append(df_temp)\n",
    "        \n",
    "df_discipline_out = pd.concat(discipline_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:54.740684Z",
     "start_time": "2024-03-05T01:43:54.704683Z"
    }
   },
   "id": "221b00533c4ecc7b",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the enrollment dataset to calculate metrics by number of enrollment\n",
    "df_enrollment = pd.read_csv(\"data/urban_institute/ccd_schools_states_enrollment.csv\")\n",
    "\n",
    "# Merge discipline data with enrollment data\n",
    "df_discipline_out = df_discipline_out.merge(right=df_enrollment,\n",
    "                                            on=[\"year\", 'date', 'country', 'fips', \"state\", \"race\", 'race_name', \"sex\", 'sex_name'],\n",
    "                                            how=\"left\")\n",
    "\n",
    "# Calculate total behavioral incidents\n",
    "df_discipline_out[\"behavioral_incidents\"] = (\n",
    "        df_discipline_out[\"students_susp_in_sch\"] + df_discipline_out[\"students_susp_out_sch\"] +\n",
    "        df_discipline_out[\"students_expulsions\"] + df_discipline_out[\"students_corporal_punish\"] + \n",
    "        df_discipline_out[\"students_arrested\"] + df_discipline_out[\"transfers_alt_sch_disc\"]\n",
    ")\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df_discipline_out.to_csv(\"data/urban_institute/crdc_schools_states_discipline.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:54.901038Z",
     "start_time": "2024-03-05T01:43:54.746505Z"
    }
   },
   "id": "fcb4522ba93fbf4",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create separate CSV files for the discipline data without racial or sex information for the Disciplinary Actions per Enrollment in the Google Looker Studio dashboard."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ebb46e0044fc2c3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Aggregate discipline data at a state level\n",
    "df_discipline_out = df_discipline_out.groupby([\"year\", 'date', 'country', 'fips', \"state\", \"race\", 'race_name'],\n",
    "                                              as_index=False).agg({\n",
    "    \"students_susp_in_sch\": \"sum\",\n",
    "    \"students_susp_out_sch\": \"sum\",\n",
    "    \"students_expulsions\": \"sum\",\n",
    "    \"students_corporal_punish\": \"sum\",\n",
    "    \"students_arrested\": \"sum\",\n",
    "    \"transfers_alt_sch_disc\": \"sum\",\n",
    "    \"behavioral_incidents\": \"sum\",\n",
    "    \"enrollment\": \"sum\"\n",
    "})\n",
    "\n",
    "# Calculate disciplinary actions per enrollment without sex information\n",
    "df_discipline_out[\"behavioral_prop_enrollment\"] = df_discipline_out[\"behavioral_incidents\"] / df_discipline_out[\n",
    "    \"enrollment\"]\n",
    "\n",
    "# Aggregate the data at a state level\n",
    "df_discipline_agg = df_discipline_out.groupby([\"year\", 'date', 'country', 'fips', \"state\"], as_index=False).agg({\n",
    "    \"behavioral_prop_enrollment\": \"sum\",\n",
    "})\n",
    "df_discipline_agg = df_discipline_agg.rename(columns={\"behavioral_prop_enrollment\": \"behavioral_prop_enrollment_total\"})\n",
    "\n",
    "df_discipline_out = df_discipline_out.merge(right=df_discipline_agg, on=[\"year\", 'date', 'country', 'fips', \"state\"])\n",
    "\n",
    "# Calculate the percentage of disciplinary actions per enrollment\n",
    "df_discipline_out[\"behavioral_prop_enrollment\"] = (df_discipline_out[\"behavioral_prop_enrollment\"] * 100 / df_discipline_out[\"behavioral_prop_enrollment_total\"])\n",
    "\n",
    "# Convert to integer and drop the intermediate column\n",
    "df_discipline_out[\"behavioral_prop_enrollment\"] = df_discipline_out[\"behavioral_prop_enrollment\"].astype(int)\n",
    "df_discipline_out.drop(columns=\"behavioral_prop_enrollment_total\", inplace=True)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df_discipline_out.to_csv(\"data/urban_institute/crdc_schools_states_discipline_no_sex.csv\", index=False)\n",
    "\n",
    "# Calculate disciplinary actions per enrollment without race and sex information\n",
    "df_discipline_out = pd.read_csv(\"data/urban_institute/crdc_schools_states_discipline.csv\")\n",
    "df_discipline_out = df_discipline_out[df_discipline_out[\"year\"] > 2019]\n",
    "df_discipline_out = df_discipline_out.groupby(['country', 'fips', \"state\"], as_index=False).agg({\n",
    "    \"behavioral_incidents\": \"sum\",\n",
    "    \"enrollment\": \"sum\"\n",
    "})\n",
    "df_discipline_out[\"behavioral_per_enrollment\"] = df_discipline_out[\"behavioral_incidents\"] / df_discipline_out[\n",
    "    \"enrollment\"]\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df_discipline_out.to_csv(\"data/urban_institute/crdc_schools_states_discipline_no_sex_no_race.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:54.958173Z",
     "start_time": "2024-03-05T01:43:54.904010Z"
    }
   },
   "id": "782dee39e742c6dd",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Teachers information Dataset\n",
    "\n",
    "I extract the teacher information dataset, transform it, and finally, load it into a CSV file. This dataset comprises one file encompassing all the years."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "249bcbed2f4f9d9d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/q05bl7gj7jxb0qq6rb67fp4m0000gn/T/ipykernel_9159/1036997871.py:2: DtypeWarning: Columns (0,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  teachers_df = pd.read_csv(\"https://educationdata.urban.org/csv/crdc/schools_crdc_teacher.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load the teacher dataset\n",
    "teachers_df = pd.read_csv(\"https://educationdata.urban.org/csv/crdc/schools_crdc_teacher.csv\")\n",
    "\n",
    "if not teachers_df.empty:\n",
    "    \n",
    "    # Remove unwanted data and handle missing values       \n",
    "    teachers_df.loc[teachers_df[\"fips\"] < 0, \"fips\"] = np.nan\n",
    "        \n",
    "    teachers_df.loc[teachers_df[\"teachers_fte_crdc\"] < 0, \"teachers_fte_crdc\"] = 0\n",
    "    teachers_df.loc[teachers_df[\"teachers_certified_fte\"] < 0, \"teachers_certified_fte\"] = 0\n",
    "    teachers_df.loc[teachers_df[\"teachers_uncertified_fte\"] < 0, \"teachers_uncertified_fte\"] = 0\n",
    "    teachers_df.loc[teachers_df[\"teachers_first_year_fte\"] < 0, \"teachers_first_year_fte\"] = 0\n",
    "    teachers_df.loc[teachers_df[\"teachers_second_year_fte\"] < 0, \"teachers_second_year_fte\"] = 0\n",
    "    teachers_df.loc[teachers_df[\"teachers_absent_fte\"] < 0, \"teachers_absent_fte\"] = 0\n",
    "    \n",
    "    # Add state information\n",
    "    teachers_df[\"state\"] = teachers_df['fips'].apply(lambda x: fips_dict[x] if x in fips_dict else np.nan)\n",
    "    \n",
    "    # Drop rows with missing state information\n",
    "    teachers_df.dropna(subset=['fips', 'state'], inplace=True)\n",
    "    \n",
    "    # Handle missing values\n",
    "    teachers_df[\"teachers_fte_crdc\"] = teachers_df[\"teachers_fte_crdc\"].fillna(0)\n",
    "    teachers_df[\"teachers_certified_fte\"] = teachers_df[\"teachers_certified_fte\"].fillna(0)\n",
    "    teachers_df[\"teachers_uncertified_fte\"] = teachers_df[\"teachers_uncertified_fte\"].fillna(0)\n",
    "    teachers_df[\"teachers_first_year_fte\"] = teachers_df[\"teachers_first_year_fte\"].fillna(0)\n",
    "    teachers_df[\"teachers_second_year_fte\"] = teachers_df[\"teachers_second_year_fte\"].fillna(0)\n",
    "    teachers_df[\"teachers_absent_fte\"] = teachers_df[\"teachers_absent_fte\"].fillna(0)\n",
    "    \n",
    "    # Convert data types\n",
    "    teachers_df[\"teachers_fte_crdc\"] = teachers_df[\"teachers_fte_crdc\"].astype(int)\n",
    "    teachers_df[\"teachers_certified_fte\"] = teachers_df[\"teachers_certified_fte\"].astype(int)\n",
    "    teachers_df[\"teachers_uncertified_fte\"] = teachers_df[\"teachers_uncertified_fte\"].astype(int)\n",
    "    teachers_df[\"teachers_first_year_fte\"] = teachers_df[\"teachers_first_year_fte\"].astype(int)\n",
    "    teachers_df[\"teachers_second_year_fte\"] = teachers_df[\"teachers_second_year_fte\"].astype(int)\n",
    "    teachers_df[\"teachers_absent_fte\"] = teachers_df[\"teachers_absent_fte\"].astype(int)\n",
    "\n",
    "    # Add country information\n",
    "    teachers_df['country'] = \"United States\"\n",
    "    # Add date information\n",
    "    teachers_df[\"day\"] = 1\n",
    "    teachers_df[\"month\"] = 1\n",
    "    teachers_df['date'] = pd.to_datetime(teachers_df[[\"year\",\"month\",\"day\"]])\n",
    "    \n",
    "    # Aggregate data at a state level\n",
    "    teachers_df = teachers_df.groupby([\"year\", 'date', 'country', \"fips\", \"state\"], as_index=False).agg({\n",
    "        \"teachers_fte_crdc\": \"sum\",\n",
    "        \"teachers_certified_fte\": \"sum\",\n",
    "        \"teachers_uncertified_fte\": \"sum\",\n",
    "        \"teachers_first_year_fte\": \"sum\",\n",
    "        \"teachers_second_year_fte\": \"sum\",\n",
    "        \"teachers_absent_fte\": \"sum\",\n",
    "    })\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:56.243710Z",
     "start_time": "2024-03-05T01:43:54.960849Z"
    }
   },
   "id": "e5f9d2ba04bc4e0e",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read the teachers data for the year 2017 and copy as 2020\n",
    "df_teachers_2020 = teachers_df[teachers_df[\"year\"] == 2017].copy()\n",
    "\n",
    "df_teachers_2020[\"year\"] = 2020\n",
    "df_teachers_2020[\"day\"] = 1\n",
    "df_teachers_2020[\"month\"] = 1\n",
    "df_teachers_2020['date'] = pd.to_datetime(df_teachers_2020[[\"year\",\"month\",\"day\"]])\n",
    "df_teachers_2020['date'] = df_teachers_2020['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "df_teachers_2020.drop(columns=['day', 'month'], inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_teachers = pd.concat([teachers_df, df_teachers_2020])\n",
    "df_teachers.to_csv(\"data/urban_institute/crdc_schools_states_teachers.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:56.252777Z",
     "start_time": "2024-03-05T01:43:56.247783Z"
    }
   },
   "id": "fa3dc9ad2178691c",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## School Finance Dataset\n",
    "\n",
    "Finally, I extract the School Finance information, transform it, and load it into a CSV file. This dataset comprises one file encompassing all the years."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "914c01a1a0aa505d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/q05bl7gj7jxb0qq6rb67fp4m0000gn/T/ipykernel_9159/2780407147.py:2: DtypeWarning: Columns (0,2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  finance_df = pd.read_csv(\"https://educationdata.urban.org/csv/crdc/schools_crdc_finance.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Read the finance dataset\n",
    "finance_df = pd.read_csv(\"https://educationdata.urban.org/csv/crdc/schools_crdc_finance.csv\")\n",
    "\n",
    "if not finance_df.empty:\n",
    "    \n",
    "    # Handle missing or negative values\n",
    "    finance_df.loc[finance_df[\"fips\"] < 0, \"fips\"] = np.nan\n",
    "    finance_df.loc[finance_df[\"salaries_teachers\"] < 0, \"salaries_teachers\"] = 0\n",
    "    finance_df.loc[finance_df[\"salaries_total\"] < 0, \"salaries_total\"] = 0\n",
    "    finance_df.loc[finance_df[\"expenditures_nonpersonnel\"] < 0, \"expenditures_nonpersonnel\"] = 0\n",
    "    finance_df.loc[finance_df[\"support_fte\"] < 0, \"support_fte\"] = 0\n",
    "    finance_df.loc[finance_df[\"administration_fte\"] < 0, \"administration_fte\"] = 0\n",
    "    finance_df.loc[finance_df[\"salaries_support\"] < 0, \"salaries_support\"] = 0\n",
    "    finance_df.loc[finance_df[\"salaries_administration\"] < 0, \"salaries_administration\"] = 0\n",
    "    \n",
    "    # Assign state information\n",
    "    finance_df[\"state\"] = finance_df['fips'].apply(lambda x: fips_dict[x] if x in fips_dict else np.nan)\n",
    "    \n",
    "    # Drop rows with missing state information\n",
    "    finance_df.dropna(subset=['fips', 'state'], inplace=True)\n",
    "    \n",
    "    # Convert columns to integer type\n",
    "    finance_df[\"salaries_teachers\"] = finance_df[\"salaries_teachers\"].fillna(0)\n",
    "    finance_df[\"salaries_total\"] = finance_df[\"salaries_total\"].fillna(0)\n",
    "    finance_df[\"expenditures_nonpersonnel\"] = finance_df[\"expenditures_nonpersonnel\"].fillna(0)\n",
    "    finance_df[\"support_fte\"] = finance_df[\"support_fte\"].fillna(0)\n",
    "    finance_df[\"administration_fte\"] = finance_df[\"administration_fte\"].fillna(0)\n",
    "    finance_df[\"salaries_support\"] = finance_df[\"salaries_support\"].fillna(0)\n",
    "    finance_df[\"salaries_administration\"] = finance_df[\"salaries_administration\"].fillna(0)\n",
    "    \n",
    "    finance_df[\"salaries_teachers\"] = finance_df[\"salaries_teachers\"].astype(int)\n",
    "    finance_df[\"salaries_total\"] = finance_df[\"salaries_total\"].astype(int)\n",
    "    finance_df[\"expenditures_nonpersonnel\"] = finance_df[\"expenditures_nonpersonnel\"].astype(int)\n",
    "    finance_df[\"support_fte\"] = finance_df[\"support_fte\"].astype(int)\n",
    "    finance_df[\"administration_fte\"] = finance_df[\"administration_fte\"].astype(int)\n",
    "    finance_df[\"salaries_support\"] = finance_df[\"salaries_support\"].astype(int)\n",
    "    finance_df[\"salaries_administration\"] = finance_df[\"salaries_administration\"].astype(int)\n",
    "    \n",
    "    # Add country information and date\n",
    "    finance_df['country'] = \"United States\"\n",
    "    finance_df[\"day\"] = 1\n",
    "    finance_df[\"month\"] = 1\n",
    "    finance_df['date'] = pd.to_datetime(finance_df[[\"year\",\"month\",\"day\"]])\n",
    "    \n",
    "    # Group data by year, state, and FIPS code and calculate aggregates\n",
    "    finance_df = finance_df.groupby([\"year\", 'date', 'country', \"fips\", \"state\"], as_index=False).agg({\n",
    "        \"salaries_teachers\": [\"sum\", \"mean\"],\n",
    "        \"salaries_total\": [\"sum\", \"mean\"],\n",
    "        \"expenditures_nonpersonnel\": \"sum\",\n",
    "        \"support_fte\": \"sum\",\n",
    "        \"administration_fte\": \"sum\",\n",
    "        \"salaries_support\": [\"sum\", \"mean\"],\n",
    "        \"salaries_administration\": [\"sum\", \"mean\"],\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    flat_cols = []\n",
    "    for i in finance_df.columns:\n",
    "        if i[1]:\n",
    "            flat_cols.append(i[0]+'_'+i[1])\n",
    "        else:\n",
    "            flat_cols.append(i[0])\n",
    "    finance_df.columns = flat_cols\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    finance_df.to_csv(f\"data/raw/urban_institute/crdc_schools_states_finance_all.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:57.321323Z",
     "start_time": "2024-03-05T01:43:56.252130Z"
    }
   },
   "id": "8c76e89178c18230",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read the school finance data for the year 2017 and copy as 2020\n",
    "df_finance_2020 = finance_df[finance_df[\"year\"] == 2017].copy()\n",
    "df_finance_2020[\"year\"] = 2020\n",
    "df_finance_2020[\"day\"] = 1\n",
    "df_finance_2020[\"month\"] = 1\n",
    "df_finance_2020['date'] = pd.to_datetime(df_finance_2020[[\"year\",\"month\",\"day\"]])\n",
    "df_finance_2020['date'] = df_finance_2020['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "df_finance_2020.drop(columns=['day', 'month'], inplace=True)\n",
    "\n",
    "df_finance = pd.concat([finance_df, df_finance_2020])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:57.327701Z",
     "start_time": "2024-03-05T01:43:57.322480Z"
    }
   },
   "id": "854862b3d899dcfb",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Read the teacher and population datasets\n",
    "df_teachers = pd.read_csv(\"./data/urban_institute/crdc_schools_states_teachers.csv\")\n",
    "df_population = pd.read_csv(\"./data/kff/population.csv\")\n",
    "df_population = df_population.groupby([\"year\", \"country\", \"state\"], as_index=False).agg({\"population\": \"sum\"})\n",
    "\n",
    "# Merge finance and population datasets based on year, country, and state\n",
    "df_finance_merged = df_finance.merge(right=df_population, on=[\"year\", \"country\", \"state\"])\n",
    "\n",
    "# Calculate financial metrics per GDP\n",
    "df_finance_merged[\"salaries_teaches_per_gdp\"] =  df_finance_merged[\"salaries_teachers_sum\"] / df_finance_merged[\"population\"]\n",
    "df_finance_merged[\"expenditures_nonpersonnel_per_gdp\"] =  df_finance_merged[\"expenditures_nonpersonnel_sum\"] / df_finance_merged[\"population\"]\n",
    "df_finance_merged[\"salaries_support_per_gdp\"] =  df_finance_merged[\"salaries_support_sum\"] / df_finance_merged[\"population\"]\n",
    "df_finance_merged[\"salaries_administration_per_gdp\"] =  df_finance_merged[\"salaries_administration_sum\"] / df_finance_merged[\"population\"]\n",
    "df_finance_merged[\"others_salaries_sum\"] = (df_finance_merged[\"salaries_total_sum\"] - df_finance_merged[\"salaries_teachers_sum\"] - df_finance_merged[\"salaries_support_sum\"] \n",
    "                                            - df_finance_merged[\"salaries_administration_sum\"])\n",
    "df_finance_merged[\"others_salaries_per_gdp\"] =  df_finance_merged[\"others_salaries_sum\"] / df_finance_merged[\"population\"]\n",
    "\n",
    "# Write the merged finance DataFrame to a CSV file\n",
    "df_finance_merged.to_csv(\"./data/urban_institute/crdc_schools_states_finance.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:57.346789Z",
     "start_time": "2024-03-05T01:43:57.329052Z"
    }
   },
   "id": "385dbd9d3e4de6dc",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Select relevant columns from the merged finance DataFrame for pie chart data\n",
    "df_finance_pie = df_finance_merged[df_finance_merged[\"year\"] > 2019][[\"year\", \"country\", \"state\", \"salaries_teaches_per_gdp\", \"expenditures_nonpersonnel_per_gdp\", \"salaries_support_per_gdp\", \"salaries_administration_per_gdp\"]]\n",
    "\n",
    "# Rename columns for better readability\n",
    "df_finance_pie = df_finance_pie.rename(columns={\n",
    "    \"salaries_administration_per_gdp\": \"Administration Salaries per Capita\",\n",
    "    \"salaries_support_per_gdp\": \"Support Salaries per Capita\",\n",
    "    \"expenditures_nonpersonnel_per_gdp\": \"Other Expenditures per Capita\",\n",
    "    \"salaries_teaches_per_gdp\": \"Teacher Salaries per Capita\"\n",
    "})\n",
    "\n",
    "# Reshape the DataFrame for pie chart visualization\n",
    "df_finance_pie = df_finance_pie.melt(id_vars=[\"year\", \"country\", \"state\"], value_vars=[\"Administration Salaries per Capita\", \"Support Salaries per Capita\", \"Other Expenditures per Capita\", \"Teacher Salaries per Capita\"], var_name='category', value_name='expenditures')\n",
    "\n",
    "# Write the reshaped DataFrame to a CSV file for pie chart visualization\n",
    "df_finance_pie.to_csv(\"./data/urban_institute/crdc_schools_states_finance_pie.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:57.353382Z",
     "start_time": "2024-03-05T01:43:57.349890Z"
    }
   },
   "id": "afa4bbf4c674b607",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I obtain the data for the map showing teachers per 1000 people."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "905c188e9b0cd5a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Select relevant columns from the finance DataFrame\n",
    "df_finance_temp = df_finance[[\"year\", \"country\", \"state\", \"salaries_teachers_sum\"]]\n",
    "# Filter teachers DataFrame for years greater than 2019\n",
    "df_teachers = df_teachers[df_teachers[\"year\"] > 2019]\n",
    "\n",
    "# Merge teachers DataFrame with finance DataFrame based on year, country, and state\n",
    "df_teachers = df_teachers.merge(right=df_finance_temp, on= [\"year\", \"country\", \"state\"] )\n",
    "# Merge teachers DataFrame with population DataFrame based on year, country, and state\n",
    "df_teachers = df_teachers.merge(right=df_population, on= [\"year\", \"country\", \"state\"] )\n",
    "\n",
    "# Calculate total number of teachers\n",
    "df_teachers[\"total_teachers\"] = df_teachers[\"teachers_fte_crdc\"] + df_teachers[\"teachers_certified_fte\"] + df_teachers[\"teachers_first_year_fte\"] + df_teachers[\"teachers_second_year_fte\"]\n",
    "\n",
    "# Calculate number of teachers per 1000 people\n",
    "df_teachers[\"teachers_per_1000people\"] = df_teachers[\"total_teachers\"] * 1000 / df_teachers[\"population\"]\n",
    "df_teachers[\"teachers_per_1000people\"] = df_teachers[\"teachers_per_1000people\"].astype(int)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df_teachers.to_csv(\"./data/urban_institute/crdc_schools_states_teachers_per_1000.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:57.360690Z",
     "start_time": "2024-03-05T01:43:57.355407Z"
    }
   },
   "id": "522b537395037d3a",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T01:43:57.363631Z",
     "start_time": "2024-03-05T01:43:57.361475Z"
    }
   },
   "id": "918fd4ce2c9e217",
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
